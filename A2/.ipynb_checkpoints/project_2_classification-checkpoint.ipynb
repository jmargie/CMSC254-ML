{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a118c506",
   "metadata": {},
   "source": [
    "# Project 2: Classification with Kernelized Perceptron\n",
    "\n",
    "## Objectives\n",
    "Your goal in this project is to get comfortable in implementing kernelized perceptron for classification. To complete this project, you should understand the following:\n",
    "\n",
    "* How to use basic math and machine learning modules in python such as numpy, matplotlib, and sklearn\n",
    "* How to train a kernel perceoptron model *from scratch*\n",
    "* How to select an approprite kernel function for a task.\n",
    "* How to perform model section when facing multiple choices\n",
    "* How to evaluate the test results and visualize the outcome of an ML model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfedf32f",
   "metadata": {},
   "source": [
    "## Deliverable\n",
    "* **Project report/writeup**: A `project2_report_lastname.pdf` file containing your **full solution**, including corresponding plots and results. Follow the `Project 2 - Report (Individual Submission)` link on Gradescope to upload this file. **The report must be self-contained**. \n",
    "  - ⚠️ <span style=\"color:red\"> [New from Project 2] </span> For coding questions, you must include the relevant code snippets and execution results (outputs/plots, if applicable) directly in this PDF. Justifications such as \"refer to the source code\" are not acceptable. \n",
    "  - The report should also include a brief justification of your solution at a high level (e.g., using relevant explanations, equations, or diagrams) and a description of your code structure (e.g., a few sentences per function).\n",
    "\n",
    "\n",
    "* **Source code**: A `project2_src_lastname1[_lastname2].ipynb` (or `.zip`) file with a working copy of your solutions compiled in a Jupyter notebook. Follow the `Project 2 - Source Code (Group Submission)` link to upload this file.\n",
    "\n",
    "\n",
    "## Logistics\n",
    "\n",
    "* You can work in groups of 1-2 students for each course project, and it's your responsibility to find a group (e.g. use Ed Discussion). \n",
    "* Every member of a group must complete and submit the project report/writeup individually. While the source code can be the same for all group members, the project report needs to be written independently by each person and, thus, should differ among team member and students more generally.\n",
    "* One one group member need to submit the source code. If you submit as a group, make sure to include your teammate in the group submission. Instructions for team submission can be found [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members).\n",
    "* Grades will be provided based on the individual project report. The source code submission will not be graded, but the teaching staff may check the source files if they see the need for reproducing your results when going through your project report. \n",
    "* Failure to submit the source code will lead to a deduction of points from your total.\n",
    "* ⚠️ <span style=\"color:red\"> [New from Project 2] </span> **Question Matching**: When uploading your PDF report to Gradescope, you must manually map your response pages to the corresponding questions. <span style=\"color:red\">  Failure to properly match questions will result in point deductions.</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9303c50",
   "metadata": {},
   "source": [
    "# Task 2A (60pts)\n",
    "In this problem, you will use perceptron to deal with a 2-D classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e864b1",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "The reference code for generating the training and test set (and plot) is provided as below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d04a9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(40)\n",
    "\n",
    "# Step 1: Define dataset parameters\n",
    "num_samples = 150\n",
    "dimensionality = 2\n",
    "num_classes = 2\n",
    "\n",
    "# Step 2: Generate random data points for each class\n",
    "mean_class1 = np.random.randn(dimensionality) * 2\n",
    "mean_class2 = np.random.randn(dimensionality) * 2 + 2.7\n",
    "\n",
    "data_class1 = mean_class1 + np.random.randn(num_samples // 2, dimensionality)\n",
    "data_class2 = mean_class2 + np.random.randn(num_samples // 2, dimensionality)\n",
    "\n",
    "# Step 3: Assign class labels (-1 for class 1 and 1 for class 2)\n",
    "labels_class1 = -np.ones(num_samples // 2)\n",
    "labels_class2 = np.ones(num_samples // 2)\n",
    "\n",
    "# Step 4: Combine data and labels, and shuffle the dataset\n",
    "data = np.vstack((data_class1, data_class2))\n",
    "labels = np.hstack((labels_class1, labels_class2))\n",
    "permutation = np.random.permutation(num_samples)\n",
    "data = data[permutation]\n",
    "labels = labels[permutation]\n",
    "\n",
    "# Split the dataset into training and testing sets (e.g., 80% training, 20% testing)\n",
    "split_ratio = 0.8\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(data, labels, test_size=1-split_ratio, random_state=42)\n",
    "\n",
    "# Visualize the dataset (optional)\n",
    "plt.scatter(data_class1[:, 0], data_class1[:, 1], label='Class 1 (negative)', marker='o')\n",
    "plt.scatter(data_class2[:, 0], data_class2[:, 1], label='Class 2 (positive)', marker='x')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736474b",
   "metadata": {},
   "source": [
    "## Task 2A.1. Perceptron (25pts)\n",
    "\n",
    "In this section, we are going to implement a binary classifier with the `Perceptron` class. \n",
    "\n",
    "<span style=\"color:red\"> TODO: </span> Fill in the code in the `Perceptron` class to implement the `fit`, `project`, and `predict` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, T=1):\n",
    "        self.T = T # number of iterations\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train perceptron model on data X with labels y and iteration T.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features, dtype=np.float64)\n",
    "        self.b = 0.0\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE\n",
    "\n",
    "    def project(self, X):\n",
    "        \"\"\"\n",
    "        Project data X onto the learned hyperplane with weights w and bias b.\n",
    "        \"\"\"\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for samples in X. Must use the project method.\n",
    "        \"\"\"\n",
    "        X = np.atleast_2d(X)\n",
    "\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46077362",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron(T=5)\n",
    "model.fit(Xtrain, ytrain)\n",
    "ypred = model.predict(Xtest)\n",
    "print('Accuracy: %.2f%%' % (np.mean(ypred == ytest) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42666ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "w = model.w\n",
    "b = model.b\n",
    "x1 = np.linspace(-5, 10, 100)\n",
    "x2 = (-w[0] * x1 - b) / w[1]\n",
    "plt.plot(x1, x2, 'k-')\n",
    "plt.scatter(data_class1[:, 0], data_class1[:, 1], label='Class 1 (negative)', marker='o')\n",
    "plt.scatter(data_class2[:, 0], data_class2[:, 1], label='Class 2 (positive)', marker='x')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77c4e4",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1. Briefly discuss your implementation of the `Perceptron` algorithm. Looking at the visualization of the training set, do you expect it to converge? Hint: Justify using the perceptron convergence theorem.\n",
    "    \n",
    "    `YOUR ANSWER STARTS HERE`\n",
    "\n",
    "- `YOUR ANSWER HERE`\n",
    "\n",
    "    `YOUR ANSWER ENDS HERE`\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea94f9",
   "metadata": {},
   "source": [
    "## Task 2A.2. Kernel Trick (35pts)\n",
    "\n",
    "Recall that in class (\"Kernel Methods\"), we discussed the *Kernel Perceptron* algorithm. The decision function for the Kernel Perceptron is given by\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = sign\\left(\\sum_{i=1}^{n} \\alpha_i y_i k(\\mathbf{x}_i, \\mathbf{x})\\right)\n",
    "$$\n",
    "\n",
    "where $k(\\mathbf{x}_i, \\mathbf{x})$ is the kernel function, $\\alpha_i$ are the learned weights, and $y_i$ are the labels.\n",
    "\n",
    "The kernel (Gram) matrix induced by kernel function *k* over *n* data points is defined as\n",
    "\n",
    "$$\n",
    "\\mathbf{K}=\n",
    "\\left(\\begin{array}{ccc} \n",
    "k(\\mathbf{x}_1,\\mathbf{x}_1) & \\dots & k(\\mathbf{x}_1,\\mathbf{x}_n)\\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "k(\\mathbf{x}_n,\\mathbf{x}_1) & \\dots & k(\\mathbf{x}_n,\\mathbf{x}_n)\n",
    "\\end{array}\\right)\n",
    "$$ \n",
    "\n",
    "Given a test data point **x**, the predicted label is\n",
    "\n",
    "$$\n",
    "\\hat{y} = sign\\left(\\sum_{i=1}^{n} \\alpha_i y_i k(\\mathbf{x}_i, \\mathbf{x})\\right)\n",
    "$$\n",
    "\n",
    "The Kernel Perceptron algorithm iteratively updates the weights $\\alpha_i$ based on the misclassified points in the training set (please refer to lecture notes on \"kernel\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f55d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of samples per quadrant\n",
    "n = 50\n",
    "\n",
    "# Standard deviation for Gaussian distribution\n",
    "std_dev = 0.1\n",
    "\n",
    "# Quadrant 1 and 3: label 1\n",
    "q1 = np.random.normal(loc=[0.25, 0.25], scale=std_dev, size=(n, 2))\n",
    "q3 = np.random.normal(loc=[0.75, 0.75], scale=std_dev, size=(n, 2))\n",
    "\n",
    "# Quadrant 2 and 4: label -1\n",
    "q2 = np.random.normal(loc=[0.75, 0.25], scale=std_dev, size=(n, 2))\n",
    "q4 = np.random.normal(loc=[0.25, 0.75], scale=std_dev, size=(n, 2))\n",
    "\n",
    "X = np.vstack((q1, q3, q2, q4))\n",
    "y = np.hstack((np.ones(2*n), -np.ones(2*n)))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Visualize the dataset\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b266efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "def plot_decision_bounday_kernel_perceptron(model, ax=None):\n",
    "    x1 = np.linspace(0, 1, 50)\n",
    "    x2 = np.linspace(0, 1, 50)\n",
    "    xx1, xx2 = np.meshgrid(x1, x2)\n",
    "    Z = np.zeros(xx1.shape)\n",
    "    for i in range(xx1.shape[0]):\n",
    "        for j in range(xx1.shape[1]):\n",
    "            Z[i,j] = model.predict([xx1[i,j], xx2[i,j]])[0]\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the decision boundary and the data\n",
    "    contour = ax.contourf(xx1, xx2, Z, alpha=0.4)\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k')\n",
    "\n",
    "    return contour, scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebe9f23",
   "metadata": {},
   "source": [
    "Recall in lecture, we have seen different kernels for $\\mathbb{R}^d$. Here are three common kernels below:\n",
    "\n",
    "$$\n",
    "k_{\\text{poly}}(\\mathbf{x},\\mathbf{x}', d)=(1+\\mathbf{x}^\\top \\mathbf{x}')^d.\n",
    "$$\n",
    "\n",
    "$$\n",
    "k_{\\text{RBF}}(\\mathbf{x},\\mathbf{x}', \\sigma) = \\exp(-\\frac{\\lVert \\mathbf{x}-\\mathbf{x'} \\rVert^2_2}{2\\sigma^2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "k_{\\text{laplace}}(\\mathbf{x},\\mathbf{x}', \\sigma) = \\exp(-\\frac{\\lVert \\mathbf{x}-\\mathbf{x'} \\rVert _1}{\\sigma})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bf1cc7",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> TODO: </span> Fill the following code block for kernel functions and kernel perceptron. (You should *not* use the other libraries such as scikit-learn.)\n",
    "\n",
    "Hint: For calculating norms, we recommend you use the `numpy.linalg.norm` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f88ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialKernel:\n",
    "    def __init__(self, p=1):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE\n",
    "\n",
    "class GaussianKernel:\n",
    "    def __init__(self, sigma=5):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE\n",
    "\n",
    "class LaplaceKernel:\n",
    "    def __init__(self, sigma=5):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE\n",
    "\n",
    "class KernelPerceptron(object):\n",
    "    def __init__(self, kernel=PolynomialKernel(p = 1), T=1):\n",
    "        self.kernel = kernel\n",
    "        self.T = T # number of iterations\n",
    "        self.alpha = None\n",
    "        self.Xtrain = None\n",
    "        self.ytrain = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.Xtrain, self.ytrain = X, y\n",
    "        n_samples, n_features = X.shape\n",
    "        self.alpha = np.zeros(n_samples, dtype=np.float64)\n",
    "\n",
    "        # Gram matrix\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE\n",
    "\n",
    "    def project(self, X):\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8803cf12",
   "metadata": {},
   "source": [
    "### Is the data linearly separable?\n",
    "Try the linear kernel (polynomial with $p = 1$) and plot the decision boundary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e10ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## results for linear kernel\n",
    "model = KernelPerceptron(kernel=PolynomialKernel(p = 1), T=10)\n",
    "model.fit(Xtrain, ytrain)\n",
    "ypred = model.predict(Xtest)\n",
    "print('Accuracy: %.2f%%' % (accuracy_score(ytest, ypred) * 100))\n",
    "plot_decision_bounday_kernel_perceptron(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee2ade",
   "metadata": {},
   "source": [
    "### Can we do better with more powerful kernels?\n",
    "<span style=\"color:red\"> TODO: </span>  Perform regression with polynomial, Gaussian, and Laplace kernels with different parameters, and visualize the accuracy as the parameter changes. \n",
    "\n",
    "Report on their decision boundaries, accuracy, and how the number of epochs required to reach a plateau in accuracy. Analyze what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f89873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please feel free to vary the input parameters of the kernel as you see fit but please report on them in your analysis.\n",
    "model = KernelPerceptron(kernel=GaussianKernel(), T=100)\n",
    "\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a97a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KernelPerceptron(kernel=LaplaceKernel(), T=100)\n",
    "\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c425bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KernelPerceptron(kernel=PolynomialKernel(2), T=100)\n",
    "\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64eae83",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1. Report on the performance and behavior of the linear kernel (polynomial with $p = 1$) model. Do you expect this performance?\n",
    "    \n",
    "`YOUR ANSWER STARTS HERE`\n",
    "\n",
    "- `YOUR ANSWER HERE`\n",
    "\n",
    "`YOUR ANSWER ENDS HERE`\n",
    "\n",
    "2. **Briefly** discuss your implementation for the kernel perceptron. For each of the kernels (Gaussian, Laplace, and Polynomial) you implemented, report on their decision boundaries, accuracy, and how the number of epochs required to reach a plateau in accuracy. Analyze what you see qualitatively and quantitatively. \n",
    "\n",
    "`YOUR ANSWER STARTS HERE`\n",
    "\n",
    "- `YOUR ANSWER HERE`\n",
    "\n",
    "`YOUR ANSWER ENDS HERE`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a6462",
   "metadata": {},
   "source": [
    "# Task 2B: Real-World Data Analysis: Seoul Bike Rental Data (40pts)\n",
    "\n",
    "In this task, we will analyze the `SeoulBikeData.csv` dataset, which provides information about bike rentals in Seoul. The dataset includes:\n",
    "- **6 Features**: Weather-related conditions like temperature, humidity, and wind speed.\n",
    "- **1 Time Feature**: Hour of the day.\n",
    "- **Target**: The number of rented bikes, with the objective of predicting whether `Rented Bike Count > 500`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d2937",
   "metadata": {},
   "source": [
    "## Steps to Complete:\n",
    "1. **Load and Explore the Dataset**:\n",
    "   - Load the `SeoulBikeData.csv` file using `pandas`.\n",
    "   - Display descriptive statistics and visualize feature distributions (e.g., histograms, pair plots).\n",
    "\n",
    "2. **Preprocessing**:\n",
    "   - Convert `Rented Bike Count` into a binary target (`1` if > 500, else `0`).\n",
    "   - Normalize the numerical features using min-max scaling or standardization.\n",
    "\n",
    "3. **Kernel-Based Modeling**:\n",
    "     - **Polynomial Kernel**: $k_{\\text{poly}}(\\mathbf{x}, \\mathbf{x}') = (1 + \\mathbf{x}^\\top \\mathbf{x}')^d$\n",
    "     - **Gaussian Kernel (RBF)**: $k_{\\text{RBF}}(\\mathbf{x}, \\mathbf{x}') = \\exp\\left(-\\frac{\\lVert \\mathbf{x} - \\mathbf{x}' \\rVert_2^2}{2 \\sigma^2}\\right)$\n",
    "     - **Laplace Kernel**: $k_{\\text{Laplace}}(\\mathbf{x}, \\mathbf{x}') = \\exp\\left(-\\frac{\\lVert \\mathbf{x} - \\mathbf{x}' \\rVert_1}{\\sigma}\\right)$\n",
    "   - Optimize $\\sigma$ for the Laplace kernel during training using cross-validation.\n",
    "\n",
    "4. **Evaluation and Analysis**:\n",
    "   - Compare the performance of different kernels using accuracy and\n",
    "   classification reports.\n",
    "   - Visualize decision boundaries for the Laplace kernel with the optimal $\\sigma$ using principle component analysis (PCA) to project data in higher dimensional feature space to 3 dimensions. Then plot the decision boundary in the same graph to visualize. Assuming the features are linearly independent, it would take the full dimension of the feature to capture 100 percent of the variation, however if we assume the data is of low \"numerical rank\", plotting the first say 3 dominant dimension of the feature will give a good representation of the data.\n",
    "   - Use `pca_3d = PCA(n_components=3); X_pca_3d = pca_3d.fit_transform(Xtest)` followed by `pca_3d.explained_variance_ratio_` and `np.sum(explained_variance_ratio) * 100:.2f}%` to see how much of the variance is explained by 3 dominant principle component.\n",
    "\n",
    "\n",
    "## Implementation Details:\n",
    "We will start with a real-world dataset this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3fc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the data to the current directory. Change the path accordingly if needed.\n",
    "# You may use your OS tool or the following code.\n",
    "# install unzip if needed\n",
    "!unzip ./pa2_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c7cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "filename = 'data/SeoulBikeData.csv'\n",
    "df = pd.read_csv(filename).drop(['Date', 'Seasons', 'Holiday', 'Functioning Day'], axis=1)\n",
    "df = df.sample(n=1000, random_state=4)\n",
    "X = df.drop(['Rented Bike Count'],  axis=1)[[\n",
    "                                            'Hour', \n",
    "                                            'Temperature (deg C)', \n",
    "                                            'Humidity(%)', \n",
    "                                            'Visibility (10m)',\n",
    "                                            'Dew point temperature (deg C)',\n",
    "                                            'Solar Radiation (MJ/m2)',\n",
    "                                            'Rainfall(mm)'\n",
    "                                            ]]\n",
    "y = df['Rented Bike Count'].values\n",
    "# binarize y\n",
    "y = np.where(y <= 500, -1, 1)\n",
    "\n",
    "print(f\"Shape X {X.shape}\")\n",
    "print(f\"Shape y {y.shape}\")\n",
    "print(\"y distribution: \", np.unique(y, return_counts=True))\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4611565f",
   "metadata": {},
   "source": [
    "### Kernel Selection ###\n",
    "\n",
    "<span style=\"color:red\"> TODO: </span> Find a proper kernel function to solve the classification task. \n",
    "\n",
    "1. Implement Sigmoid kernel: $k_{\\text{Sigmoid}}(\\mathbf{x}, \\mathbf{x}', \\gamma, c) = \\tanh\\left(\\gamma \\mathbf{x}^\\top \\mathbf{x}' + c \\right)$\n",
    "\n",
    "2. Use two other kernels used in 2A, namely `PolynomialKernel` and `GaussianKernel`. \n",
    "\n",
    "3. Try to optimize hyperparameter(s) of each kernel. Please do a bit of background research and complete the following subtasks:\n",
    "    - Step-1: Select a range of 5 values for the parameters that seem reasonable.\n",
    "    - Step-2: Select the optimal hyperparameter based on create the additional `val` split from the training data.\n",
    "    - Step-3: Train a model using the best hyperparameter(s) on the whole training set and test the model on the test set. Justify in your report your choice for the 5 values. \n",
    "\n",
    "4. Then **answer questions** at the end of this section based on your observation and analysis. \n",
    "\n",
    "*Note: Depending on your implementation, this may take several minutes to run. If you find that it is taking prohibitively long, try to optimize your code. A reasonable accuracy can range from 60% to 80% depending on the selected kernel.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc30126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidKernel(object):\n",
    "    def __init__(self, gamma=1, c=0):\n",
    "        self.gamma = gamma\n",
    "        self.c = c\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e85610",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xval = Xtrain[:int(len(Xtrain)*0.8)], Xtrain[int(len(Xtrain)*0.8):]\n",
    "ytrain, yval = ytrain[:int(len(ytrain)*0.8)], ytrain[int(len(ytrain)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cebc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best p for the Polynomial kernel\n",
    "candidate_ps = []\n",
    "best_p = 0\n",
    "best_acc = 0\n",
    "# step-1: pick up 5 reasonable values for p -- please fill values for candidate_ps\n",
    "# step-2: then try to select optimal p based on the additional \"val\" set \n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE\n",
    "print(f\"Best p: {best_p} with val accuracy {best_acc}\")\n",
    "\n",
    "# step-3: test on test set using the best_p\n",
    "ypred = np.zeros_like(ytest)\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE\n",
    "print('Accuracy: %.2f%%' % (accuracy_score(ytest, ypred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54095e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best sigma for Gaussian kernel, think about what we did in the Polynomial kernel?\n",
    "candidate_sigmas = []\n",
    "best_sigma = 0\n",
    "best_acc = 0\n",
    "# what would be our step-1 and step-2 here?\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE\n",
    "print(f\"Best sigma: {best_sigma} with val accuracy {best_acc}\")\n",
    "\n",
    "# what would be our step-3?\n",
    "ypred = np.zeros_like(ytest)\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE\n",
    "\n",
    "print('Accuracy: %.2f%%' % (accuracy_score(ytest, ypred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best gamma and c for Sigmoid kernel\n",
    "# just adapt what you did for Polynomial kernel and Gaussian kernel!\n",
    "# take care we now have two hyperparameters -- so as long as there are >=5 combinations of gamma and c, we should be good!\n",
    "best_gamma = 0\n",
    "best_c = 0\n",
    "best_acc = 0\n",
    "candidate_gammas = []\n",
    "candidate_cs = []\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE\n",
    "\n",
    "print(f\"Best gamma: {best_gamma} and c: {best_c} with val accuracy {best_acc}\")\n",
    "\n",
    "# what would be our step-3?\n",
    "ypred = np.zeros_like(ytest)\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE\n",
    "print('Accuracy: %.2f%%' % (accuracy_score(ytest, ypred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best sigma for Laplace kernel\n",
    "best_sigma = 0\n",
    "best_acc = 0\n",
    "candidate_sigmas = []\n",
    "candidate_sigmas = [0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE\n",
    "\n",
    "print(f\"Best sigma: {best_sigma} with val accuracy: {best_acc}\")\n",
    "\n",
    "# test on test set\n",
    "# what would be our step-3?\n",
    "ypred = np.zeros_like(ytest)\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(ytest, ypred) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91785e1c",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1. Discuss how accuracy compares across all methods. What would be the best and worst kernels? And what are their accuracy scores **on test set**?\n",
    "    \n",
    "    `YOUR ANSWER STARTS HERE`\n",
    "\n",
    "- `YOUR ANSWER HERE`\n",
    "\n",
    "    `YOUR ANSWER ENDS HERE`\n",
    "    ```\n",
    "\n",
    "2. Analyze the discrepancy between the model's performance on the training set versus the unseen test set (i.e., evaluate the generalization gap). Define overfitting in terms of these metrics.\n",
    "    \n",
    "    `YOUR ANSWER STARTS HERE`\n",
    "\n",
    "- `YOUR ANSWER HERE`\n",
    "\n",
    "    `YOUR ANSWER ENDS HERE`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eef430",
   "metadata": {},
   "source": [
    "# Task 2C (Bonus) (20pts): Feature Selection\n",
    "\n",
    "In this task, we will implement and analyze 2 feature selection methods. The full dataset is re-imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b847a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "filename = 'data/SeoulBikeData.csv'\n",
    "df = pd.read_csv(filename).drop(['Date', 'Seasons', 'Holiday', 'Functioning Day'], axis=1)\n",
    "df = df.sample(n=1000, random_state=4)\n",
    "X = df.drop(['Rented Bike Count'],  axis=1)\n",
    "display(df.head())\n",
    "feature_names = X.columns\n",
    "y = df['Rented Bike Count'].values\n",
    "# binarize y\n",
    "y = np.where(y <= 500, -1, 1)\n",
    "\n",
    "print(f\"Shape X {X.shape}\")\n",
    "print(f\"Shape y {y.shape}\")\n",
    "print(\"y distribution: \", np.unique(y, return_counts=True))\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a80582",
   "metadata": {},
   "source": [
    "### Task 2C.1. Greedy forward selection (10pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e399a7",
   "metadata": {},
   "source": [
    "The first method you'll implement is the greedy forward feature selection algorithm. The metric we'll use is $k$-fold cross-validation average accuracy. Concretely, that means:\n",
    "\n",
    "Initialize $S = \\emptyset, A_0 = -1$. Then for $i = 1, \\dots, d$, find the best element to add $$s_i = \\operatorname{argmax}_{j \\in S} {A_{cv}(S \\cup \\{j\\})}$$\n",
    "with the corresponding maximum accuracy $A_i = A_{cv}(S \\cup \\{s_i\\})$, where $A_{cv}(S')$ is the average accuracy using the features $S'$ over $k$ folds of cross validation. If $A_{i+1} < A_i$, break, else set $S = S \\cup \\{s_i\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d68d2c0",
   "metadata": {},
   "source": [
    "#### Implementation of cross validation using accuracy (2pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8897814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_cross_validation(Xtrain, ytrain, model, k = 10):\n",
    "    \"\"\"Output the average over cross validation folds of model's prediction.\n",
    "\n",
    "    Args:\n",
    "        Xtrain: Set of training features\n",
    "        ytrain: Set of training labels\n",
    "        model: Model, with .fit and .predict\n",
    "        k (int, optional): Number of folds. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        Average accuracy over cross validation folds of model.\n",
    "    \"\"\"\n",
    "    m = len(ytrain)\n",
    "    fold_size = m//k\n",
    "    accuracy_list = []\n",
    "    for i in range(k):\n",
    "        train_indices = list(range(i*fold_size)) + list(range((i+1) * fold_size, m))\n",
    "        val_indices = list(range(i * fold_size, (i+1) * fold_size))\n",
    "        #! YOUR CODE STARTS HERE\n",
    "\n",
    "        #! YOUR CODE ENDS HERE\n",
    "    \n",
    "    return np.mean(accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec2146a",
   "metadata": {},
   "source": [
    "#### Implementation of the greedy forward feature selection algorithm (7pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1370dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_forward(Xtrain, ytrain, model, k = 10):\n",
    "    \"\"\"Perform greedy forward feature selection\n",
    "\n",
    "    Args:\n",
    "        Xtrain: Set of training features\n",
    "        ytrain: Set of training labels\n",
    "        model: Model, with .fit and .predict\n",
    "        k (int, optional): Number of cross validation folds. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        S: the chosen features, in the form of the list of indices of X (e.g., S = [0, 1, 3] means choosing X[:, [0, 1, 3]] as the final features)\n",
    "        best_acc_list: List of the best cross-validation accuracy as features are added. For plotting.\n",
    "    \"\"\"\n",
    "    d = Xtrain.shape[1]\n",
    "    S = []\n",
    "    best_acc_list = []\n",
    "    # ! YOUR CODE STARTS HERE\n",
    "\n",
    "    # ! YOUR CODE ENDS HERE\n",
    "        \n",
    "    return S, best_acc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97185e71",
   "metadata": {},
   "source": [
    "Use the kernel perceptron with any configuration as your model, and use the code below to generate a plot of the cross validation accuracy as features are added. The feature selection procedure might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = None\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE\n",
    "S, best_acc_list = greedy_forward(Xtrain, ytrain, my_model, k = 5)\n",
    "print(f'The chosen features are: {feature_names[S]}')\n",
    "n_features = len(S)\n",
    "plt.figure()\n",
    "plt.plot(np.arange(n_features) + 1, best_acc_list)\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(np.arange(n_features) + 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ef63d",
   "metadata": {},
   "source": [
    "#### Evaluate the performance using the chosen set of features on the test set (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dde5e7",
   "metadata": {},
   "source": [
    "Use the same model configuration as above. Use the chosen features for training, and output the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c760d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! YOUR CODE STARTS HERE\n",
    "\n",
    "#! YOUR CODE ENDS HERE\n",
    "print(f'Accuracy on the test set: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c0fcd8",
   "metadata": {},
   "source": [
    "## Task 2C.2. L-1 SVM (10pts)\n",
    "\n",
    "The second method for feature selection is the L1-SVM. The $L_1$ regularization provides an incentive for the weight vector to be sparse, i.e., using fewer features. For sake of simplicity, kernelized SVM will not be necessary here.\n",
    "\n",
    "The loss function for the L1-SVM is\n",
    "\n",
    "$$\n",
    "    L = \\frac{1}{n} \\sum_{i=1}^n \\max(0, 1 - y_i \\mathbf{w}^T \\mathbf{x}_i) + \\lambda \\lVert w \\rVert_1 \n",
    "$$\n",
    "\n",
    "where we have the hinge loss and a $L_1$ regularization term.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88997e64",
   "metadata": {},
   "source": [
    "### Implementation of the L1-SVM loss and grad functions (8pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_svm_loss_function(w, X, y, lambda_):\n",
    "    \"\"\"Loss and grad function for L1-SVM loss\n",
    "\n",
    "    Args:\n",
    "        w: weights\n",
    "        X: features\n",
    "        y: labels\n",
    "        lambda_: regularization constant\n",
    "\n",
    "    Returns:\n",
    "        loss: the L1-SVM loss\n",
    "        grad: the gradient of the loss wrt w, evaluated at the current w\n",
    "    \"\"\"\n",
    "    #! YOUR CODE STARTS HERE\n",
    "\n",
    "    #! YOUR CODE ENDS HERE\n",
    "    return loss, grad\n",
    "\n",
    "def gradient_descent_l1_svm(X, y, initial_w,  eta = 3e-4, tolerance = 1e-5, lambda_= 1, max_iter = 1000):\n",
    "    \"\"\"Perform gradient descent with the L1-SVM loss\n",
    "\n",
    "    Args:\n",
    "        X: features\n",
    "        y : labels\n",
    "        initial_w: initial weight\n",
    "        eta: learning rate\n",
    "        tolerance: convergence tolerance\n",
    "        lambda_: regularization constant\n",
    "        max_iter (int, optional): maximum number of gradient descent steps. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        w: final weight\n",
    "        loss_history: list of L1-SVM losses throughout gradient descent\n",
    "    \"\"\"\n",
    "    loss_history = []\n",
    "    prev_loss = np.inf\n",
    "    w = initial_w\n",
    "    #! YOUR CODE STARTS HERE\n",
    "\n",
    "    #! YOUR CODE ENDS HERE\n",
    "    \n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc454aee",
   "metadata": {},
   "source": [
    "### Lambda cross validation (2pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9c63b",
   "metadata": {},
   "source": [
    "The two cells below are intended to perform K-fold cross validation to select the best $\\lambda$. You do not have to make any code modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28150c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(Xtrain, ytrain, initial_w, eta, tolerance, lambda_, max_iter=1000, k = 10):\n",
    "    m = len(ytrain)\n",
    "    fold_size = m//k\n",
    "    loss_list = []\n",
    "    for i in range(k):\n",
    "        tr_idx = list(range(i*fold_size)) + list(range((i+1) * fold_size, m))\n",
    "        val_idx = list(range(i * fold_size, (i+1) * fold_size))\n",
    "        Xtrain_fold = Xtrain[tr_idx]\n",
    "        ytrain_fold = ytrain[tr_idx]\n",
    "        Xval_fold = Xtrain[val_idx]\n",
    "        yval_fold = ytrain[val_idx]        \n",
    "        w, _ = gradient_descent_l1_svm(Xtrain_fold, ytrain_fold, initial_w, eta, tolerance, lambda_, max_iter)\n",
    "        loss, _ = l1_svm_loss_function(w, Xval_fold, yval_fold, lambda_)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    return np.mean(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72907c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_list = np.logspace(-3, 0, 10)\n",
    "\n",
    "cv_errors = []\n",
    "test_errors = []\n",
    "\n",
    "initial_w = np.zeros(Xtrain.shape[1])\n",
    "eta = 0.01\n",
    "tolerance = 1e-4\n",
    "\n",
    "w_list = []\n",
    "for lambda_ in lambda_list:\n",
    "    print(f'Testing {lambda_=}')\n",
    "    w, _ = gradient_descent_l1_svm(Xtrain, ytrain, initial_w, eta, tolerance, lambda_)\n",
    "    \n",
    "    w_list.append(w)\n",
    "    cv_error = cross_validation(Xtrain, ytrain, w, eta, tolerance, lambda_)\n",
    "    cv_errors.append(cv_error)\n",
    "    \n",
    "    test_error, _ = l1_svm_loss_function(w, Xtest, ytest, lambda_)\n",
    "    test_errors.append(test_error)\n",
    "\n",
    "print(f'The best lambda is {lambda_list[np.argmin(cv_errors)]}')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lambda_list, cv_errors, label='Cross Validation Error', marker='o')\n",
    "plt.plot(lambda_list, test_errors, label='Test Error', marker='x')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.title('Cross Validation and Test Error vs Lambda')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dabb98",
   "metadata": {},
   "source": [
    "#### Discussion Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf213b3",
   "metadata": {},
   "source": [
    "1. Let's say our lambda list is fixed, and hyperparameters (such as k, num_iter, tolerance, etc.) are fixed. You don't have to take into consideration the plot above. Why might there be an issue with the lambda selection procedure above?\n",
    "   \n",
    "    `# YOUR ANSWER STARTS HERE`\n",
    "\n",
    "- `YOUR ANSWER HERE`\n",
    "\n",
    "    `# YOUR ANSWER ENDS HERE`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
